\documentclass[12pt,letterpaper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{kpfonts}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{units}
\author{Matthew Klebenow}
\title{CS 540: Introduction to Artificial Intelligence \\ Homework Assignment 3}
\date{November 16, 2012}
\begin{document}
\maketitle
\tableofcontents
\pagebreak
\section{Question 1: Probabilities}
The following two tables provide the full joint distribution for three boolean variables $X,Y$ and $Z$.
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
  \caption{$Z$}
    \begin{tabular}{rrr}
    \toprule
          & $Y$     & $\bar{Y}$ \\
    \midrule
    $X$     & $0.2$   & $0.12$ \\
    $\bar{X}$ & $0.04$  & $0.24$ \\
    \bottomrule
    \end{tabular}%
  \label{tab:ztable}%
\end{table}%
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
  \caption{$\bar{Z}$}
    \begin{tabular}{rrr}
    \toprule
          & $Y$     & $\bar{Y}$ \\
    \midrule
    $X$     & $0.1$   & $0.08$ \\
    $\bar{X}$ & $0.06$  & $0.16$ \\
    \bottomrule
    \end{tabular}%
  \label{tab:notztable}%
\end{table}%
\subsection{a) What is $P\left(\bar{Y}\right)$?}
\begin{align*}
P(\bar{Y}) &= P\left(\sum{X},\bar{Y},\sum{Z}\right)\\
&= P(X,\bar{Y},Z) + P(X,\bar{Y},\bar{Z}) + P(\bar{X},\bar{Y},Z) + P(\bar{X},\bar{Y},\bar{Z})\\
&= 0.12 + 0.08 + 0.24 + 0.16\\
\Aboxed{P\left(\bar{Y}\right) &= 0.6}
%
%P\left(\bar{Y}\right) &= P\left(\bar{Y}\middle|\sum{X},\sum{Z}\right)\\
%P\left(\bar{Y}\right) &= P\left(\bar{Y}\middle|X,Z\right) + P\left(\bar{Y}\middle|\bar{X},Z\right) + P\left(\bar{Y}\middle|X,\bar{Z}\right) + P\left(\bar{Y}\middle|\bar{X},\bar{Z}\right)\\
%P\left(\bar{Y}\right) &= 0.12+0.24+0.08+0.16\\
%\Aboxed{P\left(\bar{Y}\right) &= 0.6}
\end{align*}
\subsection{b) What is $P\left(X\middle|\bar{Y}\right)$?}
\begin{align*}
P(X|\bar{Y}) &= \frac{P(X,\bar{Y})}{P(\bar{Y})}\\
P(X,\bar{Y}) &= P(X,\bar{Y},\sum{Z})\\
&= P(X,\bar{Y},Z) + P(X,\bar{Y},\bar{Z})\\
&= 0.12 + 0.08 = 0.2\\
P(\bar{Y}) &= P(X,\bar{Y},Z) + P(X,\bar{Y},\bar{Z}) + P(\bar{X},\bar{Y},Z) + P(\bar{X},\bar{Y},\bar{Z})\\
&= 0.12 + 0.08 + 0.24 + 0.16 = 0.6\\
P(X|\bar{Y}) &= \frac{0.2}{0.6}\\
\Aboxed{P\left(X|\bar{Y}\right) &= \frac{1}{3}}
%
%P\left(X\middle|\bar{Y}\right) &= P\left(X\middle|\bar{Y},Z\right) + P\left(X\middle|\bar{Y},\bar{Z}\right)\\
%P\left(X\middle|\bar{Y}\right) &= 0.12 + 0.08\\
%\Aboxed{P\left(X\middle|\bar{Y}\right) &= 0.2}
\end{align*}
\subsection{c) What is $P\left(\bar{Z}\middle|\bar{X},Y\right)$?}
\begin{align*}
P\left(\bar{Z}\middle|\bar{X},Y\right) &= \frac{P\left(\bar{Z},\bar{X},Y\right)}{P\left(\bar{X},Y\right)}\\
P(\bar{Z},\bar{X},Y) &= 0.06\\
P(\bar{X},Y) &= P(\bar{X},Y,\sum{Z})\\
&= P(\bar{X},Y,Z) + P(\bar{X},Y,\bar{Z})\\
&= 0.04 + 0.06 = 0.1\\
P\left(\bar{Z}\middle|\bar{X},Y\right) &= \frac{0.06}{0.1}\\
\Aboxed{P\left(\bar{Z}\middle|\bar{X},Y\right) &= 0.6}
%
%\Aboxed{P\left(\bar{Z}\middle|\bar{X},Y\right) &= 0.06}
\end{align*}
\subsection*{Note on Independence}
Two events $A,B,$ are independent if:
\begin{align}
P\left(A,B\right) &= P\left(A\right) \times P\left(B\right)\label{cond1}\\
P\left(A\middle|B\right) &= P\left(A\right)\label{cond2}\\
P\left(B\middle|A\right) &= P\left(B\right)\label{cond3}
\end{align}
\subsection{d) Verify whether or not $X$ and $Y$ are independent.}
Test the conditions in the section labeled ``Independence''.
\subsubsection*{Condition 1}
We attempt to verify \eqref{cond1}.
\begin{equation*}
P\left(X,Y\right)\stackrel{?}{=}P\left(X\right)\times P\left(Y\right)
\end{equation*}
First we simplify the left hand side:
\begin{align*}
P\left(X,Y\right)&=P\left(X\right)\times P\left(Y\middle|X\right)\\
&= P(X)*\frac{P(Y,X)}{P(X)}\\
&= P(X,\sum{Y},\sum{Z})*\frac{P(X,Y,\sum{Z})}{P(X,\sum{Y},\sum{Z})}\\
&= \left(0.2+0.12+0.1+0.08\right)*\frac{0.2+0.1}{0.2+0.12+0.1+0.08}\\
&= 0.2+0.1 = 0.3\\
\Aboxed{P\left(X,Y\right) &= 0.3}
%
%P\left(X,Y\right)&=\left[X\middle|\sum{Y},\sum{Z}\right]\times\left[P\left(Y\middle|X,\sum{Z}\right)\right]\\
%P\left(X,Y\right)&=\left[0.2+0.12+0.1+0.08\right]\times\left[0.2+0.1\right]\\
%P\left(X,Y\right)&=0.5\times 0.3\\
%\Aboxed{P\left(X,Y\right)&=0.15}
\end{align*}
Next we simplify the right hand side.
\begin{align*}
P\left(X\right)\times P\left(Y\right) &= P(X,\sum{Y},\sum{Z}) \times P(Y,\sum{X},\sum{Z})\\
&= \left(0.2+0.12+0.1+0.08\right) \times \left(0.2+0.04+0.1+0.06\right)\\
&= 0.5 \times 0.4\\
\Aboxed{P\left(X\right)\times P\left(Y\right) &= 0.2}
%
%P\left(X\right)\times P\left(Y\right) &= \left[0.2+0.12+0.1+0.08\right]\times\left[1-0.6\right]\\
%P\left(X\right)\times P\left(Y\right) &= 0.5\times0.4\\
%\Aboxed{P\left(X\right)\times P\left(Y\right) &= 0.2}
\end{align*}
Now we can compare the two:
\begin{align*}
P\left(X,Y\right)&\stackrel{?}{=}P\left(X\right)\times P\left(Y\right)\\
\Aboxed{0.3 &\neq 0.2}
\end{align*}
Since \eqref{cond1} is not true, we know that $X$ and $Y$ \emph{are not} independent.
\subsection{e) Verify whether or not $Y$ and $Z$ are independent.}
\subsubsection*{Condition 1}
We attempt to verify \eqref{cond1}.
\begin{equation*}
P\left(Y,Z\right)\stackrel{?}{=}P\left(Y\right)\times P\left(Z\right)
\end{equation*}
First we simplify the left hand side:
\begin{align*}
P\left(Y,Z\right) &= P\left(Y\right) \times P\left(Z\middle|Y\right)\\
&= P(Y,\sum{X},\sum{Z}) \times\frac{P(Z,Y,\sum{X})}{P(Y,\sum{X},\sum{Z})}\\
&= P(Y,Z,\sum{X}) = P(X,Y,Z) + P(\bar{X},Y,Z) = 0.2+0.04\\
\Aboxed{P\left(Y,Z\right) &= 0.24}
%
%P\left(Y,Z\right) &= P\left(Y\middle|\sum{X},\sum{Z}\right) \times P\left(Z\middle|\sum{X},Y\right)\\
%P\left(Y,Z\right) &= \left(0.2+0.04+0.1+0.06\right) \times \left(0.2+0.04\right)\\
%P\left(Y,Z\right) &= 0.4 \times 0.24\\
%\Aboxed{P\left(Y,Z\right) &= 0.096}
\end{align*}
Now we simplify the right hand side:
\begin{align*}
P\left(Y\right) \times P\left(Z\right) &= P(Y,\sum{X},\sum{Z}) \times P(Z,\sum{X},\sum{Y})\\
&= \left(0.2+0.04+0.1+0.06\right) \times \left(0.2+0.04+0.12+0.24\right)\\
&= 0.4 \times 0.6\\
\Aboxed{P\left(Y\right) \times P\left(Z\right) &= 0.24}
%
%P\left(Y\right) \times P\left(Z\right) &= \left(0.2+0.04+0.1+0.06\right) \times \left(0.2+0.12+0.04+0.24\right)\\
%P\left(Y\right) \times P\left(Z\right) &= 0.4 \times 0.6\\
%\Aboxed{P\left(Y\right) \times P\left(Z\right) &= 0.24}
\end{align*}
Now we compare the two:
\begin{align*}
P\left(Y,Z\right)&\stackrel{?}{=}P\left(Y\right)\times P\left(Z\right)\\
\Aboxed{0.24 &= 0.24}
\end{align*}
We have satisfied \eqref{cond1}, and now must move on to the next condition.
\subsubsection*{Condition 2}
We attempt to verify \eqref{cond2}.
\begin{equation*}
P\left(Y\middle|Z\right) = P\left(Y\right)
\end{equation*}
First we simplify the left hand side:
\begin{align*}
P\left(Y\middle|Z\right) &= \frac{P(Y,Z)}{P(Z)}\\
&= \frac{P(Y,Z,\sum{X})}{P(Z,\sum{X},\sum{Y})}\\
&= \frac{0.2+0.04}{0.2+0.12+0.04+0.24} = \frac{0.24}{0.6}\\
\Aboxed{P\left(Y\middle|Z\right) &= 0.4}
\end{align*}
Next we simplify the right hand side:
\begin{align*}
P(Y) &= P(Y,\sum{X},\sum{Z})\\
&= 0.2+0.4+0.1+0.06\\
\Aboxed{P\left(Y\right) &= 0.4}
\end{align*}
Now we compare the two sides:
\begin{align*}
P\left(Y\middle|Z\right) &\stackrel{?}{=} P\left(Y\right)\\
\Aboxed{0.4 &= 0.4}
\end{align*}
We have successfully verified \eqref{cond2}. One more condition to verify!
\subsubsection*{Condition 3}
We attempt to verify \eqref{cond3}.
\begin{equation*}
P\left(Z\middle|Y\right) = P\left(Z\right)
\end{equation*}
First we simplify the left hand side:
\begin{align*}
P\left(Z\middle|Y\right) &= \frac{P(Z,Y)}{P(Y)}\\
&= \frac{P(Z,Y,\sum{X})}{P(Y,\sum{X},\sum{Z})}\\
&= \frac{0.2+0.04}{0.2+0.04+0.1+0.06} = \frac{0.24}{0.4}\\
\Aboxed{P\left(Z\middle|Y\right) &= 0.6}
\end{align*}
Next we simplify the right hand side:
\begin{align*}
P(Z) &= P(Z,\sum{X},\sum{Y})\\
&= 0.2+0.12+0.04+0.24\\
\Aboxed{P(Z) &= 0.6}
\end{align*}
Now we compare the two sides:
\begin{align*}
P\left(Z\middle|Y\right) &\stackrel{?}{=} P\left(Z\right)\\
\Aboxed{0.6 &= 0.6}
\end{align*}
We have satisfied \eqref{cond3}.
\subsubsection*{Conclusion}
We have satisfied \eqref{cond1}, \eqref{cond2}, and \eqref{cond3}. Therefore, we can conclude that $Y$ and $Z$ \emph{are} independent.
\section{Question 2: Neural Networks}
The following problems were answered using the provided neural network on page 2 of ``hw3v2.pdf''. Note that all bias nodes $b$ have an output of $1$.
\subsection*{Definition of linear perceptron output}
\begin{align}
\label{lin_per}
a &= \sum_{d=0..D}{w_d \times x_d}\\
\label{sig}
\sigma\left(x\right) &= \frac{1}{1+e^{\left(-w'x\right)}}
\end{align}
Output of all nodes with inputs $x_i$ and weights $w_i$ are calculated with \eqref{lin_per}, and the classification is designated by the sigmoid function \eqref{sig}.
\subsection{a) Calculate the output of this network for the input $\left\lbrace x_1=0,x_2=1\right\rbrace$.}
\subsubsection*{$h_1$}
First we calculate the value of $w'x$ for $h_1$ with \eqref{lin_per}:
\begin{align*}
w'x_{h_1} &= -1*b + 2*x_1 + 1*x_2\\
w'x_{h_1} &= -1*1 + 2*0 + 1*1\\
w'x_{h_1} &= -1+1\\
\Aboxed{w'x_{h_1} &= 0}
\end{align*}
Now we apply \eqref{sig} to find $h_1$:
\begin{align*}
h_1 &= \sigma\left(w'x_{h_1}\right)\\
h_1 &= \frac{1}{1+e^{\left(-w'x_{h_1}\right)}}\\
h_1 &= \frac{1}{1+e^{\left(0\right)}}\\
\Aboxed{h_1 &= \frac{1}{2}}
\end{align*}
\subsubsection*{$h_2$}
Now we calculate the value of $w'x$ for $h_2$ with \eqref{lin_per}:
\begin{align*}
w'x_{h_2} &= 0.5*b - 3*x_1 - 2*x_2\\
w'x_{h_2} &= 0.5*1 - 3*0 - 2*1\\
w'x_{h_2} &= 0.5 - 2\\
\Aboxed{w'x_{h_2} &= -1.5}
\end{align*}
Next we apply \eqref{sig} to find $h_2$:
\begin{align*}
h_2 &= \sigma\left(w'x_{h_2}\right)\\
h_2 &= \frac{1}{1+e^{\left(-w'x_{h_2}\right)}}\\
h_2 &= \frac{1}{1+e^{\left(1.5\right)}}\\
h_2 &= 0.1824255238\\
\Aboxed{h_2 &\approx 0.18}
\end{align*}
\subsubsection*{$k$}
Finally, we can calculate $w'x$ for $k$ with \eqref{lin_per}:
\begin{align*}
w'x_k &= -0.5*b - 1*h_1 + 0.8*h_2\\
w'x_k &= -0.5*1 - 1*0 + 0.8*\left(-1.5\right)\\
w'x_k &= -0.5 - 1.2\\
\Aboxed{w'x_k &= -1.7}
\end{align*}
Again, we apply \eqref{sig} to find $k$:
\begin{align*}
k &= \sigma\left(w'x_{k}\right)\\
k &= \frac{1}{1+e^{\left(-w'x_{k}\right)}}\\
k &= \frac{1}{1+e^{\left(1.7\right)}}\\
k &= 0.1544652651\\
\Aboxed{k &\approx 0.15}
\end{align*}
Thus the output of the network will be $y\approx0.15$.
\subsection{b) Now you are going to compute one step of the backpropagation algorithm. The weights of the output node $k$ (red node) are fixed. The input for the training instance is $\left\lbrace x_1=0,x_2=1\right\rbrace$ and the output of this training instance is $y=1$. Please compute the updated weights for the hidden layer (the two blue nodes) by performing ONE step of gradient descent. Let the step size $\alpha$ equal $0.1$.}
For output unit k, compute error term $\delta_k$:
\begin{align*}
\delta_k &\leftarrow \left(o_k-y_k\right)o_k\left(1-o_k\right)\\
\delta_k &\leftarrow \left(0.15-1.\right) * 0.15 * \left(1-0.15\right)\\
\delta_k &\leftarrow -0.85 * 0.15 * 0.85\\
\Aboxed{\delta_k &\leftarrow 0.11}
\end{align*}
Now compute error term for hidden node $h_1$:
\begin{align*}
\delta_{h_1} &\leftarrow \left(\sum_{i\in succ(h_1)}{w_{ih_1}\delta_i}\right)o_{h_1}\left(1-o_{h_1}\right)\\
\delta_{h_1} &\leftarrow \left(w_{kh_1}\delta_k\right)o_{h_1}\left(1-o_{h_1}\right)\\
\delta_{h_1} &\leftarrow \left(-1*0.11\right)*\frac{1}{2}*\left(1-\frac{1}{2}\right)\\
\Aboxed{\delta_{h_1} &\leftarrow -0.0275}
\end{align*}
The error term for node $h_2$ is similar:
\begin{align*}
\delta_{h_2} &\leftarrow \left(w_{kh_2}\delta_k\right)o_{h_2}\left(1-o_{h_2}\right)\\
\delta_{h_2} &\leftarrow \left(0.8*0.11\right)*0.18*\left(1-0.18\right)\\
\Aboxed{\delta_{h_2} &\leftarrow 0.131}
\end{align*}
Now we need to update all non-fixed weights with \eqref{weightUp}.
\begin{equation}
\label{weightUp}
w_{ji} \leftarrow w_{ji}-\alpha\delta_jx_{ji}
\end{equation}
\begin{itemize}
\item $w_{h_ib}$
\item $w_{h_i x_1}$
\item $w_{h_i x_2}$
\end{itemize}
\subsubsection*{$w_{bh_i}$}
\begin{align*}
w_{h_1b} &\leftarrow w_{h_1b} - \alpha\delta_{h_1}b\\
w_{h_1b} &\leftarrow -1 - 0.1*-0.0275*1\\
\Aboxed{w_{h_1b} &\leftarrow -0.99725}
\end{align*}
\begin{align*}
w_{h_2b} &\leftarrow w_{h_2b} - \alpha\delta_{h_2}b\\
w_{h_2b} &\leftarrow 0.5 - 0.1*0.131*1\\
\Aboxed{w_{h_2b} &\leftarrow 0.4869}
\end{align*}
\subsubsection*{$w_{h_i x_1}$}
\begin{align*}
w_{h_1x_1} &\leftarrow w_{h_1x_1} - \alpha\delta_{h_1}x_1\\
w_{h_1x_1} &\leftarrow 2 - 0.1*-0.0275*0\\
\Aboxed{w_{h_1x_1} &\leftarrow 2}
\end{align*}
\begin{align*}
w_{h_2x_1} &\leftarrow w_{h_2x_1} - \alpha\delta_{h_2}x_1\\
w_{h_2x_1} &\leftarrow -3 - 0\\
\Aboxed{w_{h_2x_1} &\leftarrow -3}
\end{align*}
\subsubsection*{$w_{h_i x_2}$}
\begin{align*}
w_{h_1x_2} &\leftarrow w_{h_1x_2} - \alpha\delta_{h_1}x_2\\
w_{h_1x_2} &\leftarrow 1 - 0.1*-0.0275*1\\
\Aboxed{w_{h_1x_2} &\leftarrow -0.99725}
\end{align*}
\begin{align*}
w_{h_2x_2} &\leftarrow w_{h_2x_2} - \alpha\delta_{h_2}x_2\\
w_{h_2x_2} &\leftarrow -2 - 0.1*0.131*1\\
\Aboxed{w_{h_2x_2} &\leftarrow -2.0131}
\end{align*}
\subsubsection{Answers}
All weights have been updated. To maintain good organization, all final weight values have been listed below.\footnote{Note that $w_{ji}$ is the weight from unit $i$ to unit $j$.}
\begin{itemize}
\item $w_{h_1b} \leftarrow -0.99725$
\item $w_{h_2b} \leftarrow 0.4869$
\item $w_{h_1x_1} \leftarrow 2$
\item $w_{h_2x_1} \leftarrow -3$
\item $w_{h_1x_2} \leftarrow -0.99725$
\item $w_{h_2x_2} \leftarrow -2.0131$
\end{itemize}
\section{Question 3: Bayes Nets}
All questions in this section were addressed using the Bayes Net provided in ``hw3v2.pdf'' on page 3.\\
Note the following abbreviations that will be employed:
\begin{itemize}
\item Storm $\rightarrow S$
\item Camp Fire $\rightarrow CF$
\item Lightning $\rightarrow L$
\item Thunder $\rightarrow T$
\item Forest Fire $\rightarrow FF$
\end{itemize}
\subsection{a) What is the probability of a forest fire?}
The probability of a forest fire is the sum of probabilities of a forest fire joint with all other possible sets of events.
\begin{align*}
\Pr\left(FF\right) &= \Pr\left(FF,\sum{L},\sum{CF}\right)\\
\Pr\left(FF\right) &= \Pr\left(FF,L,CF\right) + \Pr\left(FF,L,\bar{CF}\right) + \Pr\left(FF,\bar{L},CF\right) + \Pr\left(FF,\bar{L},\bar{CF}\right)\\
\Pr\left(FF\right) &= \left[\Pr(FF|L,CF)\Pr(L)\Pr(CF)\right] + \left[\Pr(FF|L,\bar{CF})\Pr(L)\Pr(\bar{CF})\right]\\
&+\left[\Pr(FF|\bar{L},CF)\Pr(\bar{L})\Pr(CF)\right] + \left[\Pr(FF|\bar{L},\bar{CF})\Pr(\bar{L})\Pr(\bar{CF})\right]\\
\Pr(L) &= \Pr\left(L,\sum{S}\right) = \Pr(L|S)\Pr(S) + \Pr(L|\bar{S})\Pr(\bar{S})\\
\Pr(L) &= 0.5*0.1 + 0.05*0.9\\
\Pr(L) &= 0.05+0.045=0.095\\
\Pr(\bar{L}) &= \Pr\left(\bar{L},\sum{S}\right) = \Pr(\bar{L}|S)\Pr(S) + \Pr(\bar{L}|\bar{S})\Pr(\bar{S})\\
\Pr(\bar{L}) &= 0.5*0.1 + 0.95*0.9\\
\Pr(\bar{L}) &= 0.05+0.855 = 0.905\\
\Pr\left(FF\right) &= \left[0.5*0.095*0.75\right] + \left[0.4*0.095*0.25\right]\\
&+\left[0.1*0.905*0.75\right] + \left[0.01*0.905*0.25\right]\\
\Pr\left(FF\right) &= \left[0.035625\right] + \left[0.0095\right]\\
&+\left[0.067875\right] + \left[0.0022625\right]\\
\Pr\left(FF\right) &= 0.1152625\\
\Aboxed{\Pr\left(FF\right) &\approx 0.115}
\end{align*}
\subsection{b) What is the probability of a forest fire given thunder?}
\begin{align*}
\Pr(FF|T) &= \frac{\Pr(FF,T)}{\Pr(T)}\\
\Pr(FF,T) &= \Pr\left(FF,T,\sum{CF},\sum{L},\sum{S}\right)\\
\Pr(FF,T) &= \Pr(FF,T,CF,L,S) + \Pr(FF,T,CF,L,\bar{S})\\
&+ \Pr(FF,T,CF,\bar{L},S) + \Pr(FF,T,CF,\bar{L},\bar{S})\\
&+ \Pr(FF,T,\bar{CF},L,S) + \Pr(FF,T,\bar{CF},L,\bar{S})\\
&+ \Pr(FF,T,\bar{CF},\bar{L},S) + \Pr(FF,T,\bar{CF},\bar{L},\bar{S})\\
\Pr(FF,T,CF,L,S) &= \Pr(FF|L,C)\Pr(T|L)\Pr(CF)\Pr(L|S)\Pr(S)\\
&= 0.5*0.95*0.75*0.5*0.1 = 0.0178125\\
\Pr(FF,T,CF,L,\bar{S}) &= \Pr(FF|L,C)\Pr(T|L)\Pr(CF)\Pr(L|\bar{S})\Pr(\bar{S})\\
&= 0.5*0.95*0.75*0.05*0.9 = 0.01603125\\
\Pr(FF,T,CF,\bar{L},S) &= \Pr(FF|\bar{L},CF)\Pr(T|\bar{L})\Pr(CF)\Pr(\bar{L}|S)\Pr(S)\\
&= 0.1*0.2*0.75*0.5*0.1 = 0.00075\\
\Pr(FF,T,CF,\bar{L},\bar{S}) &= \Pr(FF|\bar{L},CF)\Pr(T|\bar{L})\Pr(CF)\Pr(\bar{L}|\bar{S})\Pr(\bar{S})\\
&= 0.1*0.2*0.75*0.95*0.9 = 0.012825\\
\Pr(FF,T,\bar{CF},L,S) &= \Pr(FF|L,\bar{CF})\Pr(T|L)\Pr(\bar{CF})\Pr(L|S)\Pr(S)\\
&= 0.4*0.95*0.25*0.5*0.1 = 0.00475\\
\Pr(FF,T,\bar{CF},L,\bar{S}) &= \Pr(FF|L,\bar{CF})\Pr(T|L)\Pr(\bar{CF})\Pr(L|\bar{S})\Pr(\bar{S})\\
&= 0.4*0.95*0.25*0.05*0.9 = 0.004275\\
\Pr(FF,T,\bar{CF},\bar{L},S) &= \Pr(FF|\bar{L},\bar{CF})\Pr(T|\bar{L})\Pr(\bar{CF})\Pr(\bar{L}|S)\Pr(S)\\
&= 0.01*0.2*0.25*0.5*0.1 = 0.000025\\
\Pr(FF,T,\bar{CF},\bar{L},\bar{S}) &= \Pr(FF|\bar{L},\bar{CF})\Pr(T|\bar{L})\Pr(\bar{CF})\Pr(\bar{L}|\bar{S})\Pr(\bar{S})\\
&= 0.01*0.2*0.25*0.95*0.9 = 0.0004275\\
\Pr(FF,T) &= 0.0178125+0.01603125+0.00075+0.012825\\
&+0.00475+0.004275+0.000025+0.0004275\\
\Pr(FF,T) &= 0.05689625\\
\Pr(T) &= \Pr(T,\sum{L}) = \Pr(T,L) + \Pr(T,\bar{L})\\
\Pr(T) &= \Pr(T|L)\Pr(L) + \Pr(T|\bar{L})\Pr(\bar{L})\\
\Pr(T) &= 0.95*0.095 + 0.2*0.905 = 0.27125\\
\Pr(FF|T) &= \frac{0.05689625}{0.27125}\\
\Pr(FF|T) &= 0.20975576036866359447004608294931\\
\Aboxed{\Pr\left(FF\middle|T\right) &\approx 0.21}
\end{align*}
\subsection{c) What is the probability that there is a storm given that there is a forest fire?}
\begin{align*}
\Pr(S|FF) &= \frac{\Pr(S,FF)}{\Pr(FF)}\\
\Pr(S,FF) &= \Pr\left(S,FF,\sum{L},\sum{CF}\right)\\
&= \Pr(S,FF,L,CF) + \Pr(S,FF,L,\bar{CF}) + \Pr(S,FF,\bar{L},CF) + \Pr(S,FF,\bar{L},\bar{CF})\\
\Pr(S,FF,L,CF) &= \Pr(S)\Pr(FF|L,CF)\Pr(L|S)\Pr(CF)\\
&= 0.1*0.5*0.5*0.75 = 0.01875\\
\Pr(S,FF,L,\bar{CF}) &= \Pr(S)\Pr(FF|L,\bar{CF})\Pr(L|S)\Pr(\bar{CF})\\
&= 0.1*0.4*0.5*0.25 = 0.005\\
\Pr(S,FF,\bar{L},CF) &= \Pr(S)\Pr(FF|\bar{L},CF)\Pr(\bar{L}|S)\Pr(CF)\\
&= 0.1*0.1*0.5*0.75 = 0.00375\\
\Pr(S,FF,\bar{L},\bar{CF}) &= \Pr(S)\Pr(FF|\bar{L},\bar{CF})\Pr(\bar{L}|S)\Pr(\bar{CF})\\
&= 0.1*0.01*0.5*0.25 = 0.000125\\
\Pr(S,FF) &= 0.01875+0.005+0.00375+0.000125=0.027625\\
\Pr(FF) &= 0.1152625\\
\Pr(S|FF) &= 0.23967031775295521093156924411669\\
\Aboxed{\Pr\left(S\middle|FF\right) &\approx 0.24}
\end{align*}
\subsection{d) What is the probability of thunder given that there is no storm?}
\begin{align*}
\Pr(T|\bar{S}) &= \frac{\Pr(T,\bar{S})}{\Pr(\bar{S})}\\
\Pr(T,\bar{S}) &= \Pr(T,\bar{S},\sum{L})\\
&= \Pr(T,\bar{S},L) + \Pr(T,\bar{S},\bar{L})\\
&= \Pr(T|L)\Pr(\bar{S})\Pr(L|\bar{S}) + \Pr(T|\bar{L})\Pr(\bar{S})\Pr(\bar{L}|\bar{S})\\
&= 0.95*0.9*0.05 + 0.2*0.9*0.95 = 0.04275 + 0.171\\
&= 0.21375\\
\Pr(\bar{S}) &= 0.9\\
\Pr(T|\bar{S}) &= \frac{0.21375}{0.9}\\
\Aboxed{\Pr\left(T\middle|\bar{S}\right) &= 0.2375}
\end{align*}
\subsection{e) What is the probability of a camp fire and a forest fire?}
\begin{align*}
\Pr(CF,FF) &= \Pr(CF,FF,\sum{L})\\
&= \Pr(CF,FF,L) + \Pr(CF,FF,\bar{L})\\
&= \Pr(CF)\Pr(FF|CF,L)\Pr(L) + \Pr(CF)\Pr(FF|CF,\bar{L})\Pr(\bar{L})\\
&= 0.75*0.5*0.095 + 0.75*0.1*0.905 = 0.035625 + 0.067875\\
\Aboxed{\Pr\left(CF,FF\right) &= 0.1035}
\end{align*}
\section*{Question 4: Spam Classification with a Na\"{i}ve Bayes Classifier}
This work has been completed separately and handed in electronically.
\end{document}
%
% Failed attempt at backprop
%\subsubsection*{Definitions}
%\begin{equation}
%\label{err}
%E=\frac{1}{2}\sum_{i=1..N}{a_i-y_i}^2
%\end{equation}
%\eqref{err} is our definition of ``error''. We further define the gradient descent rule \eqref{gradDesc}.
%\begin{equation}
%\label{gradDesc}
%W \leftarrow W-\alpha\nabla E\left(W\right)
%\end{equation}
%Step by step, we carry out \eqref{gradDesc} by:
%\begin{align*}
%E\left(W\right) &= \frac{1}{2}\sum_{i=1..N}{\left(a_i-y_i\right)^2}\\
%\frac{\partial E}{\partial wd} &= \sum_{i=1..N}{\left(a_i-y_i\right)x_i d}\\
%wd&\leftarrow wd-\alpha\sum_{i=1..N}{\left(a_i-y_i\right)x_i d}
%\end{align*}
%\subsubsection*{Gradient Descent}
%First we find the error through \eqref{err}.
%\begin{align*}
%E &= \frac{1}{2}\sum_{i=1..N}{a_i-y_i}^2\\
%E &= \frac{1}{2}\left(1-0.15\right)^2\\
%E &= 0.36125
%\end{align*}
%Next we find the partial derivative:
%\begin{align*}
%\frac{\partial E}{\partial wd} &= \sum_{i=1..N}{\left(a_i-y_i\right)x_i d}\\
%\frac{\partial E}{\partial wd} &= 
%\end{align*}